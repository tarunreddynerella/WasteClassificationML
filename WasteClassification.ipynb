{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip install opencv-python\n",
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming and combining datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_files_in_category(base_dir, category):\n",
    "    for sub_dir in ['Train', 'Test']:\n",
    "        path = os.path.join(base_dir, category, sub_dir)\n",
    "        files = os.listdir(path)\n",
    "\n",
    "        for i, filename in enumerate(sorted(files), start=1):\n",
    "            old_filepath = os.path.join(path, filename)\n",
    "            new_filename = f\"{category}_{i:02d}.jpg\"\n",
    "            new_filepath = os.path.join(path, new_filename)\n",
    "\n",
    "            os.rename(old_filepath, new_filepath)\n",
    "            print(f\"Renamed '{old_filepath}' to '{new_filepath}'\")\n",
    "\n",
    "# Base directory where the new data is stored\n",
    "base_dir = \"./archive 2\"\n",
    "\n",
    "# List of categories\n",
    "categories = [\"Compost\", \"Hazardous\", \"Recycle\", \"Trash\"]\n",
    "\n",
    "# Renaming all the files in each category\n",
    "for category in categories:\n",
    "    rename_files_in_category(base_dir, category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"./archive 2\"\n",
    "\n",
    "# Sub-directories for train and test sets\n",
    "sub_dirs = ['train', 'test']\n",
    "\n",
    "for sub_dir in sub_dirs:\n",
    "    data_path = os.path.join(base_path, sub_dir)\n",
    "\n",
    "    for class_name in os.listdir(data_path):\n",
    "        class_path = os.path.join(data_path, class_name)\n",
    "\n",
    "        # Only process if it's a directory, not empty, and not a .DS_Store file\n",
    "        if os.path.isdir(class_path) and os.listdir(class_path) and not class_name.startswith('.'):\n",
    "            img_name = os.listdir(class_path)[0]  # Get the first image name\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "\n",
    "            # Convert the image for visualization\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "                plt.title(f\"{sub_dir} - {class_name}\")\n",
    "                plt.show()\n",
    "            else:\n",
    "                print(f\"Failed to load image: {img_path}\")\n",
    "        elif class_name.startswith('.'):\n",
    "            print(f\"Skipping hidden file: {class_name}\")\n",
    "        else:\n",
    "            print(f\"No images found in {class_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    img = tf.image.rgb_to_grayscale(img)\n",
    "    img = tf.image.resize(img, (128, 128))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentation and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = os.path.join(base_path, 'train')\n",
    "validation_data_path = os.path.join(base_path, 'test')\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Setting up the training data generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_path,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'  # Multi-class classification\n",
    ")\n",
    "\n",
    "# Validation data generator\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_path,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Balancing : Class weights Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the class weights to handle class imbalance\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator.classes),\n",
    "    y=train_generator.classes\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Output class weights for reference\n",
    "print(\"Class Weights: \", class_weights_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling problematic Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(data_path):\n",
    "    problematic_files = []\n",
    "\n",
    "    for subdir, dirs, files in os.walk(data_path):\n",
    "        for file in files:\n",
    "            filepath = os.path.join(subdir, file)\n",
    "\n",
    "            # Removing .DS_Store files\n",
    "            if file == '.DS_Store':\n",
    "                os.remove(filepath)\n",
    "                print(f\"Removed system file: {filepath}\")\n",
    "                continue\n",
    "\n",
    "            #corrupt images\n",
    "            if not filepath.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                continue\n",
    "\n",
    "            img = cv2.imread(filepath)\n",
    "            if img is None:\n",
    "                problematic_files.append(filepath)\n",
    "\n",
    "    return problematic_files\n",
    "\n",
    "data_path = './archive 2'\n",
    "problematic_files = clean_dataset(data_path)\n",
    "\n",
    "if problematic_files:\n",
    "    print(\"Problematic files:\")\n",
    "    for file in problematic_files:\n",
    "        print(file)\n",
    "else:\n",
    "    print(\"No problematic files found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(128, 128, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Dense(4, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with a learning rate scheduler\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Early stopping and model checkpoint callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "lr_schedule = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.00001)\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    validation_data=validation_generator,\n",
    "    class_weight=class_weights_dict,\n",
    "    callbacks=[early_stopping, model_checkpoint, lr_schedule],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot training & validation accuracy and loss values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Validation Accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Validation Loss: {val_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo using webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_image_from_webcam():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open camera\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return frame\n",
    "\n",
    "image = capture_image_from_webcam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, target_size=(128, 128)):\n",
    "    img = cv2.imread(image_path) \n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img / 255.0\n",
    "    img = img.reshape(1, target_size[0], target_size[1], 3) \n",
    "    return img\n",
    "\n",
    "# Preprocess the captured image\n",
    "preprocessed_image = preprocess_image('image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the class\n",
    "prediction = model.predict(preprocessed_image)\n",
    "class_idx = np.argmax(prediction, axis=1)\n",
    "\n",
    "\n",
    "class_names = ['Compost', 'Hazardous', 'Recyclables', 'Trash']\n",
    "predicted_class = class_names[class_idx[0]]\n",
    "print(f\"Predicted Class: {predicted_class}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
